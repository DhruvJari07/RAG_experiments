{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain openai faiss-cpu tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv(\"Huggingface_api\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "yolo_nas_loader = WebBaseLoader(\"https://deci.ai/blog/yolo-nas-object-detection-foundation-model/\").load()\n",
    "decicoder_loader = WebBaseLoader(\"https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/\").load()\n",
    "yolo_newsletter_loader = WebBaseLoader(\"https://deeplearningdaily.substack.com/p/unleashing-the-power-of-yolo-nas\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='\\n\\n\\n\\n\\n\\nYOLO-NAS by Deci Achieves State-of-the-Art Performance on Object Detection Using Neural Architecture Search\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n \\n \\n\\n\\n\\n\\n\\n\\n\\nPlatform\\n\\nCOMPUTER VISION\\nModels\\nCustom Models\\nTrain\\nGENERATIVE AI\\nModels\\nDeployment\\n\\n\\nTechnology\\nSolutions\\n\\nUSE CASES\\nOptimize Generative AI Models\\nRun on Edge Devices\\nReduce Cloud Cost\\nShorten Development Time\\nMaximize Data Center Utilization\\nINDUSTRIES\\nAutomotive\\nSmart Retail\\nPublic Sector\\nSmart Manufacturing\\nVideo Analytics\\n\\n\\nPricing\\nResources\\n\\nResource Center\\nBlog\\nGlossary\\nModel Zoo\\nThe Deep Learning Podcast\\nNeural Architecture Search 101\\nQuantization Aware Training 101\\nDeci University\\nCV Dataset Profiling & Analysis\\nEfficient CV Model Training\\nDL Inference Acceleration\\nDownload Guide\\n\\n\\nCommunity\\nCompany\\n\\nAbout Us\\nCareers\\nPartners\\nNewsroom\\nContact Us\\n\\n\\n \\n\\n Menu\\n\\n\\nPlatform\\n\\nCOMPUTER VISION\\nModels\\nCustom Models\\nTrain\\nGENERATIVE AI\\nModels\\nDeployment\\n\\n\\nTechnology\\nSolutions\\n\\nUSE CASES\\nOptimize Generative AI Models\\nRun on Edge Devices\\nReduce Cloud Cost\\nShorten Development Time\\nMaximize Data Center Utilization\\nINDUSTRIES\\nAutomotive\\nSmart Retail\\nPublic Sector\\nSmart Manufacturing\\nVideo Analytics\\n\\n\\nPricing\\nResources\\n\\nResource Center\\nBlog\\nGlossary\\nModel Zoo\\nThe Deep Learning Podcast\\nNeural Architecture Search 101\\nQuantization Aware Training 101\\nDeci University\\nCV Dataset Profiling & Analysis\\nEfficient CV Model Training\\nDL Inference Acceleration\\nDownload Guide\\n\\n\\nCommunity\\nCompany\\n\\nAbout Us\\nCareers\\nPartners\\nNewsroom\\nContact Us\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nLog in \\n\\n\\n\\n\\n\\n\\nBook a Demo\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGet Started\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\nBack to Blog\\n\\n\\n\\n\\n\\n\\n\\nAlgorithms \\n\\n\\n\\nYOLO-NAS by Deci Achieves SOTA Performance on Object Detection Using Neural Architecture Search \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nBy\\nDeci \\n\\n\\n\\n \\n\\nResearch Team \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMay 3, 2023 \\n\\n\\n\\n \\n\\n10 min read \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nAuthors:\\n\\nEugene Khvedchenya, Deep Learning Research Engineer\\nHarpreet Sahota, DevRel Manager\\n\\nIntroduction\\nObject detection has revolutionized how machines perceive and interpret the world around them.\\nIt‚Äôs a crucial task in computer vision, enabling machines to recognize and locate objects within images or videos. Over the years, this technology has become increasingly robust and accurate, making it indispensable across many applications that shape our modern world, such as autonomous vehicles, facial recognition systems, and more. One key factor that has driven the progress of object detection is the discovery of powerful neural network architectures. The discovery of powerful neural network architectures has driven the advancement of object detection, enhancing the capabilities of computer vision.\\nIn particular, architectures such as Faster R-CNN and YOLO have been instrumental in shaping modern object detection architectures.\\nYOLO, which stands for You Only Look Once, is one of the most popular and successful approaches to object detection.\\nThe first version of YOLO was introduced in 2016 and changed how object detection was performed by treating object detection as a single regression problem. It divided images into a grid and simultaneously predicted bounding boxes and class probabilities. Though it was faster than previous object detection methods, YOLOv1 had limitations in detecting small objects and struggled with localization accuracy. Since the first YOLO architecture hit the scene, several YOLO-based architectures have been developed, all known for their accuracy, real-time performance, and enabling object detection on edge devices and in the cloud.\\nYOLOv6, YOLOv7, and YOLOv8 are the current state-of-the-art models from the YOLO family, building on the success of YOLOv5.\\nBut just because we have all these YOLOs doesn‚Äôt mean that deep learning for object detection is a dormant area of research.\\nDeveloping a new YOLO-based architecture can redefine state-of-the-art (SOTA) object detection by addressing the existing limitations and incorporating recent advancements in deep learning. Imagine a new YOLO-based architecture that could enhance your ability to detect small objects, improve localization accuracy, and increase the performance-per-compute ratio, making the model more accessible for real-time edge-device applications.\\nBy pushing the boundaries of accuracy and efficiency, a new YOLO architecture could become a benchmark for object detection, driving innovation and unlocking new possibilities across many industries and research domains. And that‚Äôs precisely what we‚Äôve done here at Deci.\\nIn this post, we‚Äôd like to introduce you to our new architecture ‚Äì YOLO-NAS.\\n\\nAt Deci, we are committed to advancing the frontier of AI development by constantly pushing ourselves to improve. The tradeoff between accuracy and latency is well-known to deep learning practitioners. Accuracy often comes at the cost of time; the most precise models are typically the slowest. Our tools enable teams to overcome this and other challenges and allow them to develop fast and accurate models. Our success in addressing this task has positioned us as leaders in the field.\\n\\n\\nFigure 1. Efficiency Frontier plot for object detection on the COCO2017 dataset (validation) comparing YOLO-NAS vs other YOLO architectures.\\nTL;DR: What‚Äôs New in the YOLO-NAS Architecture? \\n\\nThe use of QSP and QCI blocks combine re-parameterization and 8-bit quantization advantages. These blocks rely on an approach suggested by Chu et al.\\xa0Blocks allow for minimal accuracy loss during post-training quantization.\\xa0\\nDeci‚Äôs proprietary NAS technology, AutoNAC, was used to determine optimal sizes and structures of stages, including block type, number of blocks, and number of channels in each stage.\\xa0\\nA hybrid quantization method that selectively quantizes certain parts of a model, reducing information loss and balancing latency and accuracy. Standard quantization affects all model layers, often leading to significant accuracy loss. Our hybrid method optimizes quantization to maintain accuracy by only quantizing certain layers while leaving others untouched. Our layer selection algorithm considers each layer‚Äôs impact on accuracy and latency, as well as the effects of switching between 8-bit and 16-bit quantization on overall latency.\\nA pre-training regimen that includes automatically labeled data, self-distillation, and large datasets.\\xa0\\nThe YOLO-NAS architecture is available under an open-source license. Its‚Äô pre-trained weights are available for research use (non-commercial) on SuperGradients, Deci‚Äôs PyTorch-based, open-source, computer vision training library.\\n\\nThe new YOLO-NAS architecture sets a new frontier for object detection tasks, offering the best accuracy and latency tradeoff performance.\\nThis balance outperforms existing models today, setting a new standard for state-of-the-art (SOTA) object detection. Designed specifically for production use, YOLO-NAS is fully compatible with high-performance inference engines like NVIDIA¬Æ TensorRT‚Ñ¢ and supports INT8 quantization for unprecedented runtime performance.\\nThis optimization allows YOLO-NAS to excel in real-world scenarios, such as autonomous vehicles, robotics, and video analytics applications, where low latency and efficient processing are essential.\\nThe model‚Äôs innovative architecture also leverages cutting-edge techniques, such as attention mechanisms, quantization aware blocks, and reparametrization at inference time to further improve its object detection capabilities. These contribute to YOLO-NAS‚Äôs exceptional performance in detecting objects of varying sizes and complexities, creating a new gold standard for use cases across industries.\\nAs you‚Äôll learn in this post, YOLO-NAS sets a new benchmark for object detection models regarding the accuracy and latency tradeoffs.\\nWe Used Deep Learning to Find a New Deep Learning Architecture!\\nInspired by the success of the most recent YOLO architecture, YOLOv8, our researchers challenged themselves to find a more performant architecture.\\nUtilizing our proprietary neural architecture search (NAS) algorithm, The Automated Neural Architecture Construction (AutoNAC) engine, our research team discovered a new architecture that outperforms YOLOv8.\\n\\nWe used machine learning to find a new deep learning architecture!\\n\\nWhy do it this way?\\nFinding the ‚Äúright‚Äù architecture by hand is extremely tedious and inefficient. So, we applied AutoNAC to discover novel object detection models optimized to minimize inference latency computed over NVIDIA‚Äôs T4\\xa0 ‚Äì a widely used cloud GPU. AutoNAC used a neural design space incorporating SOTA architectural design principles and Deci‚Äôs novel neural elements.\\nUtilizing NAS offers significant advantages over manual exploration.\\nNAS algorithms can systematically explore the vast search space of potential architectures, effectively identifying novel and optimized configurations that might be overlooked by human intuition. By automating the process, these algorithms can efficiently evaluate and compare a vast number of candidate architectures, ultimately converging on a solution that optimally balances accuracy, speed, and complexity.\\nAlthough Neural Architecture Search (NAS) has been suggested to automate the development of better artificial neural networks that outperform manually-designed architectures, it has been deemed impractical due to the significant resource requirements it entails. Only large companies with extensive computing resources have utilized NAS, making it inaccessible to most developers. AutoNAC has introduced a solution to this problem by bringing into play a new, fast, and compute-efficient generation of NAS algorithms allowing it to operate cost-effectively and at scale.\\xa0\\nThe AutoNAC engine is hardware and data-aware and considers all the components in the inference stack, including compilers and quantization.\\nTo create YOLO-NAS, our research team started with an unfathomable search space of 10^14 possible architectures.\\nOur AutoNAC engine traversed this search space and honed in on the region we call ‚Äúthe efficiency frontier.‚Äù AutoNAC explores and maps the efficiency frontier, searching for an architecture that best balances latency vs. throughput. We sample three points of this frontier to create the YOLO-NASS, YOLO-NASM, and YOLO-NASL architectures.\\nOur data-driven approach accelerated the discovery of this innovative architecture, with the entire process taking roughly 3800 GPU hours.\\nReducing reliance on manual intervention and invention empowers the development of more efficient, robust, and versatile deep learning models for various applications.\\n\\nAutoNAC is an efficient NAS algorithm used by Deci‚Äôs customers to automatically construct efficient deep learning models for any task and hardware.\\n\\nDuring the NAS process, we incorporated quantization-aware RepVGG blocks into the model architecture, ensuring that our model architecture would be compatible with Post-Training Quantization (PTQ).\\nFigure 2. YOLO-NAS High-Level Architecture Overview\\nTraining Details\\nYOLO-NAS‚Äôs multi-phase training process involves pre-training on Object365, COCO Pseudo-Labeled data, Knowledge Distillation (KD), and Distribution Focal Loss (DFL).\\nThe model is pre-trained on Objects365, a comprehensive dataset with 2 million images and 365 categories, for 25-40 epochs (depending on the model variant) due to the extensive time needed for each epoch (each epoch takes 50-80 minutes on 8 NVIDIA RTX A5000 GPUs). The COCO dataset provides an additional 123k unlabeled images, which are used to generate pseudo-labelled data. An <accurate model> is trained on COCO to label these images, which are then used to train our model with the original 118k train images.\\nThe YOLO-NAS architecture also incorporates Knowledge Distillation (KD) and Distribution Focal Loss (DFL) to enhance its training process.\\nKnowledge Distillation is applied by adding a KD term to the loss function, enabling the student network to mimic the logits of both classification and DFL predictions of the teacher network. DFL is employed by learning box regression as a classification task, discretizing box predictions into finite values, and predicting distributions over these values, which are then converted to final predictions through a weighted sum.\\n\\nFigure 3. Efficiency Frontier plot for object detection on the COCO2017 dataset (validation) comparing YOLO-NAS vs other YOLO architectures.\\nQuantization Aware Architecture\\nYOLO-NAS‚Äôs architecture employs quantization-aware blocks and selective quantization for optimized performance.\\nThe model‚Äôs design features adaptive quantization, skipping quantization in specific layers based on the balance between latency/throughput improvement and accuracy loss. When converted to its INT8 quantized version, YOLO-NAS experiences a smaller precision drop (0.51, 0.65, and 0.45 points of mAP for S, M, and L variants) compared to other models that lose 1-2 mAP points during quantization. These techniques culminate in innovative architecture with superior object detection capabilities and top-notch performance.\\nThe YOLO-NAS architecture and pre-trained weights define a new frontier in low-latency inference and an excellent starting point for fine-tuning downstream tasks.\\nUse Cases\\n\\n\\n\\nStrong pre-trained weights often lead to higher model accuracy on new datasets when fine-tuning.\\nYOLO-NAS was trained on the RoboFlow100 dataset (RF100), a collection of 100 datasets from diverse domains, to demonstrate its ability to handle complex object detection tasks. The RF100 dataset is a benchmark for existing YOLO models, enabling us to compare YOLO-NAS‚Äôs performance against them and showcase its advantages.\\n\\nFigure 4. Examples of annotated images in the RF100 benchmark.\\xa0\\nWe followed the RF100 repository‚Äôs training protocol to ensure a fair comparison.\\nThe training protocol for the model includes the following settings, applied consistently across all datasets for 100 epochs on a single T4 GPU with 16GB of VRAM during training:\\n\\nLearning rate: 5e-4 for the Small version and 4e-4 for the Medium version of the model\\nWeight decay: 1e-4 (excluding bias and BatchNorm layers)\\nExponential moving average (EMA) with a decay factor of 0.99\\nBatch size: 16\\nImage resolution: 640√ó640\\n\\nThese hyperparameters ensure a robust and consistent training process, allowing for a fair comparison of the model‚Äôs performance across different datasets.\\nBelow are the results obtained by focusing on the ‚ÄúSmall‚Äù and ‚ÄúMedium‚Äù YOLO-NAS variants.\\n\\nFigure 5. Average mAP on Roboflow-100 for YOLO-NAS vs other models.\\nDue to the unavailability of mAP scores for some datasets for the YOLO v5/v7/v8 models, we compared YOLO-NAS‚Äôs performance only on datasets with available scores. YOLO-NAS was successfully trained on all 100 datasets without issues, providing a comprehensive comparison.\\nBelow is a per-category breakdown of YOLO-NAS‚Äôs performance on the RF-100 dataset, compared to the performance of v5/v7/v8 models:\\n\\nFigure 6. Per category mAP score for YOLO-NAS vs other models.Note: For Yolo vV5/v7/v8, we used the results reported here.\\nTo support the open-source community, we have released the capability to fine-tune YOLO-NAS models on the RF100 dataset within the SuperGradients library. This feature is available in SuperGradients version 3.10 and above, making it easier for users to leverage our models for improved performance on diverse tasks.\\npython -m super_gradients.train_from_recipe\\n--config-name=roboflow_yolo_nas_s dataset_name=abdomen-mri\\nWe also release the ‚ÄúFine-Tuning YOLO-NAS Notebook‚Äù available here.\\n\\nYOLO-NAS can be easily fine-tuned to achieve state-of-the-art results using Google Colab Notebook. With the help of SuperGradients, transfer learning becomes even more seamless and efficient, allowing for quick adaptation to new tasks and datasets.\\n\\nA Small Note on Used Hyperparameters\\nFinding the optimal hyperparameters for each dataset individually can be tedious.\\nTo avoid overfitting hyperparameters for each dataset, we took 10 random subsets from RF100 and performed a short grid search across learning rate, weight decay, and EMA settings. Our goal was to find a set of parameters that lead to the maximum average mAP, ensuring a robust solution across different datasets. We then applied these hyperparameters to train YOLO-NAS on all datasets from RF100. We used a batch size of 16 for the Small (S) variant and 12 for the Medium (M) variant, ensuring an efficient training process tailored to each model version.\\n\\nFigure 7. Visualization of a sweep run to search default hyperparameters\\nPotential Impact\\nThe new object detection model, YOLO-NAS, developed by Deci using AutoNAC technology, has achieved state-of-the-art performance in object detection.\\nWe hope this breakthrough inspires new research and revolutionizes the field of computer vision, enabling machines to perceive and interact with the world more intelligently and autonomously. Regarding scalability and availability, YOLO-NAS is designed with production use in mind and is fully compatible with inference engines like NVIDIATensorRT, ensuring seamless deployment. YOLO-NAS offers a practical and scalable solution for various computer vision applications.\\nThe SuperGradients open-source training library simplifies fine-tuning the model for downstream tasks, making it accessible to a wider audience and promoting its adoption across various applications.\\nConclusion\\nOur new object detection model has expanded the frontier in object detection.\\nThis new model is fast and accurate, offering the best accuracy-latency tradeoff among existing object detection models on the market. This accomplishment was made possible by Deci‚Äôs AutoNAC neural architecture search technology, which efficiently constructs deep learning models for any task and hardware.\\nYOLO-NAS is quantization-friendly and supports TensorRT deployment, ensuring full compatibility with production use. Ultimately, this breakthrough in object detection can inspire new research and revolutionize the field, enabling machines to perceive and interact with the world more intelligently and autonomously.\\nWe‚Äôre excited to see what you build with it!\\nResources\\nIntro to SuperGradients + YOLONAS Starter Notebook\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nYou May Also Like\\n \\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\nQualcomm Snapdragon: Optimizing YOLO Performance with Advanced SNPE Quantization \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\nThe Ultimate Guide to LLM Evaluation\\xa0 \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n \\n\\n\\n\\nTop Large Language Models Reshaping the Open-Source Arena \\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThe latest deep learning insights, tips, and best practices delivered to your inbox. \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRelated stories \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\nNLP \\n\\n\\n\\nTop Large Language Models Reshaping the Open-Source Arena \\n\\n\\n\\n\\n\\n\\n\\n \\nRead More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nDeci \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\nComputer Vision \\n\\n\\n\\nSmall Object Detection Challenges and Solutions \\n\\n\\n\\n\\n\\n\\n\\n \\nRead More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nDeci \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\nComputer Vision \\n\\n\\n\\nNavigating AI: 11 Must-Attend Sessions at GTC 2024 \\n\\n\\n\\n\\n\\n\\n\\n \\nRead More\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\nDeci \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nThis site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.  \\n\\n\\n\\n\\n\\n\\n\\n\\nTechnology\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPricing\\n\\n\\n\\n\\nResources\\n\\n\\n\\n\\nBlog\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAbout\\n\\n\\n\\n\\nCareers\\n\\n\\n\\n\\nNewsroom\\n\\n\\n\\n\\nContact Us\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\nDeci is ISO 27001\\n\\nCertified \\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n¬© 2024 Deci\\n\\n\\n\\nPrivacy Policy\\n\\n\\n\\n\\nWebsite Terms of Use\\n\\n\\n\\n\\nCV Terms of Service\\n\\n\\n\\n\\nGen AI Terms of Service\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\nLinkedin-in\\n \\n\\n\\n\\nTwitter\\n \\n\\n\\n\\n\\n \\n\\n\\n\\nVimeo-v\\n \\n\\n\\n\\nYoutube\\n \\n\\n\\n\\nFacebook-f\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nShare \\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nURL \\n\\n\\n\\n\\n\\n\\n\\n◊©◊ú◊ô◊ó◊î\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAdd Your Heading Text Here \\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\n\\t\\t\\t\\t\\tfrom transformers import AutoFeatureExtractor, AutoModelForImageClassification\\n\\nextractor = AutoFeatureExtractor.from_pretrained(\"microsoft/resnet-50\")\\n\\nmodel = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-50\")\\n\\t\\t\\t\\t\\n\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', metadata={'source': 'https://deci.ai/blog/yolo-nas-object-detection-foundation-model/', 'title': 'YOLO-NAS by Deci Achieves State-of-the-Art Performance on Object Detection Using Neural Architecture Search', 'description': 'The new YOLO-NAS architecture sets a new frontier for object detection tasks, offering the best accuracy and latency tradeoff performance.', 'language': 'en-US'})]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo_nas_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunking the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 25,\n",
    "    length_function = len\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_nas_chunks = text_splitter.transform_documents(yolo_nas_loader)\n",
    "decicoder_chunks = text_splitter.transform_documents(decicoder_loader)\n",
    "yolo_newsletter_chunks = text_splitter.transform_documents(yolo_newsletter_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = LocalFileStore(\"./cachce/\")\n",
    "\n",
    "# create an embedder\n",
    "core_embeddings_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    core_embeddings_model,\n",
    "    store,\n",
    "    namespace = \"Huggingface_embeddings\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store embeddings in vector store\n",
    "vectorstore = FAISS.from_documents(yolo_nas_chunks, embedder)\n",
    "\n",
    "vectorstore.add_documents(decicoder_chunks)\n",
    "\n",
    "vectorstore.add_documents(yolo_newsletter_chunks)\n",
    "\n",
    "# instantiate a retriever\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.llms.openai import OpenAIChat\n",
    "from langchain_community.llms import HuggingFaceHub\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.callbacks import StdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dhruv\\anaconda3\\envs\\langchain_apps\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "llm = HuggingFaceHub(repo_id=repo_id, huggingfacehub_api_token=HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler =  StdOutCallbackHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the entire retrieval system\n",
    "qa_with_sources_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    callbacks=[handler],\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dhruv\\anaconda3\\envs\\langchain_apps\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# This is the entire augment system!\n",
    "response = qa_with_sources_chain({\"query\":\"What does Neural Architecture Search have to do with how Deci creates its models?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What does Neural Architecture Search have to do with how Deci creates its models?',\n",
       " 'result': \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nDeci‚Äôs suite of Large Language Models and text-to-Image models, with DeciCoder leading the charge, is spearheading the movement to address this gap.DeciCoder‚Äôs efficiency is evident when compared to other top-tier models. Owing to its innovative architecture, DeciCoder surpasses models like SantaCoder in both accuracy and speed. The innovative elements of DeciCoder‚Äôs architecture were generated using Deci‚Äôs proprietary Neural Architecture Search technology, AutoNAC‚Ñ¢.\\xa0\\nAnother Win for AutoNAC\\n\\nto previous SOTA on COCOSuperGradients star historyDesigning the BlueprintInspired by the success of modern YOLO architectures, our team set out to create a new quantization-friendly architecture - and it all started with Neural Architecture Search (NAS).NAS:Everything You Need to KnowThe first thing you need to do when performing Neural Architecture Search is define the architecture search space. For YOLO-NAS, our researchers took inspiration from the basic blocks of YOLOv6 and YOLOv8. With\\n\\nUtilizing our proprietary neural architecture search (NAS) algorithm, The Automated Neural Architecture Construction (AutoNAC) engine, our research team discovered a new architecture that outperforms YOLOv8.\\n\\nThe quest for the ‚Äúoptimal‚Äù neural network architecture has historically been a labor-intensive manual exploration. While this manual approach often yields results, it is highly time consuming and often falls short in pinpointing the most efficient neural networks. The AI community recognized the promise of Neural Architecture Search (NAS) as a potential game-changer, automating the development of superior neural networks. However, the computational demands of traditional NAS methods limited\\n\\nQuestion: What does Neural Architecture Search have to do with how Deci creates its models?\\nHelpful Answer: Neural Architecture Search (NAS) is a technique used by Deci to automatically discover the optimal neural network architecture for its models, such as DeciCoder, using its proprietary AutoNAC algorithm. This approach allows Deci to create models that are both accurate and efficient.\",\n",
       " 'source_documents': [Document(page_content='Deci‚Äôs suite of Large Language Models and text-to-Image models, with DeciCoder leading the charge, is spearheading the movement to address this gap.DeciCoder‚Äôs efficiency is evident when compared to other top-tier models. Owing to its innovative architecture, DeciCoder surpasses models like SantaCoder in both accuracy and speed. The innovative elements of DeciCoder‚Äôs architecture were generated using Deci‚Äôs proprietary Neural Architecture Search technology, AutoNAC‚Ñ¢.\\xa0\\nAnother Win for AutoNAC', metadata={'source': 'https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/', 'title': 'Introducing DeciCoder: The New Gold Standard in Efficient and Accurate Code Generation', 'description': 'Today, we introduce DeciCoder, our 1B-parameter open-source Large Language Model for code generation, equipped with a 2048-context window.', 'language': 'en-US'}),\n",
       "  Document(page_content='to previous SOTA on COCOSuperGradients star historyDesigning the BlueprintInspired by the success of modern YOLO architectures, our team set out to create a new quantization-friendly architecture - and it all started with Neural Architecture Search (NAS).NAS:Everything You Need to KnowThe first thing you need to do when performing Neural Architecture Search is define the architecture search space. For YOLO-NAS, our researchers took inspiration from the basic blocks of YOLOv6 and YOLOv8. With', metadata={'source': 'https://deeplearningdaily.substack.com/p/unleashing-the-power-of-yolo-nas', 'title': 'Unleashing the Power of YOLO-NAS: A New Era in Object Detection and Computer Vision', 'description': 'The Future of Computer Vision is Here', 'language': 'en'}),\n",
       "  Document(page_content='Utilizing our proprietary neural architecture search (NAS) algorithm, The Automated Neural Architecture Construction (AutoNAC) engine, our research team discovered a new architecture that outperforms YOLOv8.', metadata={'source': 'https://deci.ai/blog/yolo-nas-object-detection-foundation-model/', 'title': 'YOLO-NAS by Deci Achieves State-of-the-Art Performance on Object Detection Using Neural Architecture Search', 'description': 'The new YOLO-NAS architecture sets a new frontier for object detection tasks, offering the best accuracy and latency tradeoff performance.', 'language': 'en-US'}),\n",
       "  Document(page_content='The quest for the ‚Äúoptimal‚Äù neural network architecture has historically been a labor-intensive manual exploration. While this manual approach often yields results, it is highly time consuming and often falls short in pinpointing the most efficient neural networks. The AI community recognized the promise of Neural Architecture Search (NAS) as a potential game-changer, automating the development of superior neural networks. However, the computational demands of traditional NAS methods limited', metadata={'source': 'https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/', 'title': 'Introducing DeciCoder: The New Gold Standard in Efficient and Accurate Code Generation', 'description': 'Today, we introduce DeciCoder, our 1B-parameter open-source Large Language Model for code generation, equipped with a 2048-context window.', 'language': 'en-US'})]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Deci‚Äôs suite of Large Language Models and text-to-Image models, with DeciCoder leading the charge, is spearheading the movement to address this gap.DeciCoder‚Äôs efficiency is evident when compared to other top-tier models. Owing to its innovative architecture, DeciCoder surpasses models like SantaCoder in both accuracy and speed. The innovative elements of DeciCoder‚Äôs architecture were generated using Deci‚Äôs proprietary Neural Architecture Search technology, AutoNAC‚Ñ¢.¬†\n",
      "Another Win for AutoNAC\n",
      "\n",
      "to previous SOTA on COCOSuperGradients star historyDesigning the BlueprintInspired by the success of modern YOLO architectures, our team set out to create a new quantization-friendly architecture - and it all started with Neural Architecture Search (NAS).NAS:Everything You Need to KnowThe first thing you need to do when performing Neural Architecture Search is define the architecture search space. For YOLO-NAS, our researchers took inspiration from the basic blocks of YOLOv6 and YOLOv8. With\n",
      "\n",
      "Utilizing our proprietary neural architecture search (NAS) algorithm, The Automated Neural Architecture Construction (AutoNAC) engine, our research team discovered a new architecture that outperforms YOLOv8.\n",
      "\n",
      "The quest for the ‚Äúoptimal‚Äù neural network architecture has historically been a labor-intensive manual exploration. While this manual approach often yields results, it is highly time consuming and often falls short in pinpointing the most efficient neural networks. The AI community recognized the promise of Neural Architecture Search (NAS) as a potential game-changer, automating the development of superior neural networks. However, the computational demands of traditional NAS methods limited\n",
      "\n",
      "Question: What does Neural Architecture Search have to do with how Deci creates its models?\n",
      "Helpful Answer: Neural Architecture Search (NAS) is a technique used by Deci to automatically discover the optimal neural network architecture for its models, such as DeciCoder, using its proprietary AutoNAC algorithm. This approach allows Deci to create models that are both accurate and efficient.\n"
     ]
    }
   ],
   "source": [
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Deci‚Äôs suite of Large Language Models and text-to-Image models, with DeciCoder leading the charge, is spearheading the movement to address this gap.DeciCoder‚Äôs efficiency is evident when compared to other top-tier models. Owing to its innovative architecture, DeciCoder surpasses models like SantaCoder in both accuracy and speed. The innovative elements of DeciCoder‚Äôs architecture were generated using Deci‚Äôs proprietary Neural Architecture Search technology, AutoNAC‚Ñ¢.\\xa0\\nAnother Win for AutoNAC', metadata={'source': 'https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/', 'title': 'Introducing DeciCoder: The New Gold Standard in Efficient and Accurate Code Generation', 'description': 'Today, we introduce DeciCoder, our 1B-parameter open-source Large Language Model for code generation, equipped with a 2048-context window.', 'language': 'en-US'}), Document(page_content='to previous SOTA on COCOSuperGradients star historyDesigning the BlueprintInspired by the success of modern YOLO architectures, our team set out to create a new quantization-friendly architecture - and it all started with Neural Architecture Search (NAS).NAS:Everything You Need to KnowThe first thing you need to do when performing Neural Architecture Search is define the architecture search space. For YOLO-NAS, our researchers took inspiration from the basic blocks of YOLOv6 and YOLOv8. With', metadata={'source': 'https://deeplearningdaily.substack.com/p/unleashing-the-power-of-yolo-nas', 'title': 'Unleashing the Power of YOLO-NAS: A New Era in Object Detection and Computer Vision', 'description': 'The Future of Computer Vision is Here', 'language': 'en'}), Document(page_content='Utilizing our proprietary neural architecture search (NAS) algorithm, The Automated Neural Architecture Construction (AutoNAC) engine, our research team discovered a new architecture that outperforms YOLOv8.', metadata={'source': 'https://deci.ai/blog/yolo-nas-object-detection-foundation-model/', 'title': 'YOLO-NAS by Deci Achieves State-of-the-Art Performance on Object Detection Using Neural Architecture Search', 'description': 'The new YOLO-NAS architecture sets a new frontier for object detection tasks, offering the best accuracy and latency tradeoff performance.', 'language': 'en-US'}), Document(page_content='The quest for the ‚Äúoptimal‚Äù neural network architecture has historically been a labor-intensive manual exploration. While this manual approach often yields results, it is highly time consuming and often falls short in pinpointing the most efficient neural networks. The AI community recognized the promise of Neural Architecture Search (NAS) as a potential game-changer, automating the development of superior neural networks. However, the computational demands of traditional NAS methods limited', metadata={'source': 'https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/', 'title': 'Introducing DeciCoder: The New Gold Standard in Efficient and Accurate Code Generation', 'description': 'Today, we introduce DeciCoder, our 1B-parameter open-source Large Language Model for code generation, equipped with a 2048-context window.', 'language': 'en-US'})]\n"
     ]
    }
   ],
   "source": [
    "print(response['source_documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = qa_with_sources_chain({\"query\":\"What is DeciCoder\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What is DeciCoder',\n",
       " 'result': \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nTo learn more about DeciCoder, check out the model on Hugging Face.\\n\\nReady for Commercial Applications: Beyond just experimentation and personal projects, Deci‚Äôs permissive licensing means you can confidently deploy DeciCoder in commercial applications. Whether you‚Äôre looking to enhance your product, offer new services, or simply leverage the model for business growth, DeciCoder is ready to be your partner in innovation.\\n\\nSo, what drives DeciCoder‚Äôs impressive throughput? A combination of architectural efficiency and optimized implementation. Notably, DeciCoder is significantly more memory efficient, allowing it to manage larger batch sizes. This memory efficiency means that Deci‚Äôs throughput reaches its maximum when its batch size is at 128, whereas SantaCoder capped at 32. With larger batch sizes, without the worry of running out of memory, DeciCoder effectively processes more data at once, further augmenting\\n\\nBroad Use Rights: With a permissive license, DeciCoder grants you wide-ranging rights, alleviating typical legal concerns that can accompany the use of some models. You can seamlessly integrate DeciCoder into your projects with minimal restrictions.\\n\\nQuestion: What is DeciCoder\\nHelpful Answer: DeciCoder is a text-to-text model developed by Deci, a leading company in the field of AI research. It is a permissively licensed model, meaning it can be used in commercial applications without any major legal concerns. DeciCoder is known for its impressive throughput, which is achieved through architectural efficiency and optimized implementation. It is significantly more memory efficient than other models, allowing it to manage larger batch sizes and process more data at once.\",\n",
       " 'source_documents': [Document(page_content='To learn more about DeciCoder, check out the model on Hugging Face.', metadata={'source': 'https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/', 'title': 'Introducing DeciCoder: The New Gold Standard in Efficient and Accurate Code Generation', 'description': 'Today, we introduce DeciCoder, our 1B-parameter open-source Large Language Model for code generation, equipped with a 2048-context window.', 'language': 'en-US'}),\n",
       "  Document(page_content='Ready for Commercial Applications: Beyond just experimentation and personal projects, Deci‚Äôs permissive licensing means you can confidently deploy DeciCoder in commercial applications. Whether you‚Äôre looking to enhance your product, offer new services, or simply leverage the model for business growth, DeciCoder is ready to be your partner in innovation.', metadata={'source': 'https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/', 'title': 'Introducing DeciCoder: The New Gold Standard in Efficient and Accurate Code Generation', 'description': 'Today, we introduce DeciCoder, our 1B-parameter open-source Large Language Model for code generation, equipped with a 2048-context window.', 'language': 'en-US'}),\n",
       "  Document(page_content='So, what drives DeciCoder‚Äôs impressive throughput? A combination of architectural efficiency and optimized implementation. Notably, DeciCoder is significantly more memory efficient, allowing it to manage larger batch sizes. This memory efficiency means that Deci‚Äôs throughput reaches its maximum when its batch size is at 128, whereas SantaCoder capped at 32. With larger batch sizes, without the worry of running out of memory, DeciCoder effectively processes more data at once, further augmenting', metadata={'source': 'https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/', 'title': 'Introducing DeciCoder: The New Gold Standard in Efficient and Accurate Code Generation', 'description': 'Today, we introduce DeciCoder, our 1B-parameter open-source Large Language Model for code generation, equipped with a 2048-context window.', 'language': 'en-US'}),\n",
       "  Document(page_content='Broad Use Rights: With a permissive license, DeciCoder grants you wide-ranging rights, alleviating typical legal concerns that can accompany the use of some models. You can seamlessly integrate DeciCoder into your projects with minimal restrictions.', metadata={'source': 'https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/', 'title': 'Introducing DeciCoder: The New Gold Standard in Efficient and Accurate Code Generation', 'description': 'Today, we introduce DeciCoder, our 1B-parameter open-source Large Language Model for code generation, equipped with a 2048-context window.', 'language': 'en-US'})]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DeciCoder is a text-to-text model developed by Deci, a leading company in the field of AI research. It is a permissively licensed model, meaning it can be used in commercial applications without any major legal concerns. DeciCoder is known for its impressive throughput, which is achieved through architectural efficiency and optimized implementation. It is significantly more memory efficient than other models, allowing it to manage larger batch sizes and process more data at once.\n"
     ]
    }
   ],
   "source": [
    "print(response['result'].split(':')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = qa_with_sources_chain({\"query\":\"How many version are there in YOLO\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "The first version of YOLO was introduced in 2016 and changed how object detection was performed by treating object detection as a single regression problem. It divided images into a grid and simultaneously predicted bounding boxes and class probabilities. Though it was faster than previous object detection methods, YOLOv1 had limitations in detecting small objects and struggled with localization accuracy. Since the first YOLO architecture hit the scene, several YOLO-based architectures have\n",
      "\n",
      "hesitate to reach out with any questions or feedback. The Team Behind YOLO-NASThe success of YOLO-NAS can be attributed to the hard work, dedication, and brilliance of the following individuals:Research: Amos Gropp, Ido Shahaf, Ran El-Yaniv, Akhiad BercovichEngineering: Ofri Masad, Shay Aharon, Eugene Khvedchenia, Louis Dupont, Kate YurkovaProduct: Shani Perl On behalf of the community, I thank you all for your hard work and for making YOLO-NAS a reality üëèüèΩ üôèüèΩ!Community Generated ContentIt's\n",
      "\n",
      "Figure 1. Efficiency Frontier plot for object detection on the COCO2017 dataset (validation) comparing YOLO-NAS vs other YOLO architectures.\n",
      "TL;DR: What‚Äôs New in the YOLO-NAS Architecture?\n",
      "\n",
      "By pushing the boundaries of accuracy and efficiency, a new YOLO architecture could become a benchmark for object detection, driving innovation and unlocking new possibilities across many industries and research domains. And that‚Äôs precisely what we‚Äôve done here at Deci.\n",
      "In this post, we‚Äôd like to introduce you to our new architecture ‚Äì YOLO-NAS.\n",
      "\n",
      "Question: How many version are there in YOLO\n",
      "Helpful Answer: There have been several versions of YOLO since the first one was introduced in 2016. The latest version introduced is YOLO-NAS.\n"
     ]
    }
   ],
   "source": [
    "print(response['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    task=\"text-generation\",\n",
    "    huggingfacehub_api_token = HF_TOKEN,\n",
    "    model_kwargs={\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"top_k\": 30,\n",
    "        \"temperature\": 0.1,\n",
    "        \"repetition_penalty\": 1.1,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dhruv\\anaconda3\\envs\\langchain_apps\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Dhruv\\anaconda3\\envs\\langchain_apps\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Dhruv\\.cache\\huggingface\\hub\\models--mistralai--Mistral-7B-Instruct-v0.2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the entire retrieval system\n",
    "qa_with_sources_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    callbacks=[handler],\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = qa_with_sources_chain({\"query\":\"What does Neural Architecture Search have to do with how Deci creates its models?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'What does Neural Architecture Search have to do with how Deci creates its models?',\n",
       " 'result': \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\nDeci‚Äôs suite of Large Language Models and text-to-Image models, with DeciCoder leading the charge, is spearheading the movement to address this gap.DeciCoder‚Äôs efficiency is evident when compared to other top-tier models. Owing to its innovative architecture, DeciCoder surpasses models like SantaCoder in both accuracy and speed. The innovative elements of DeciCoder‚Äôs architecture were generated using Deci‚Äôs proprietary Neural Architecture Search technology, AutoNAC‚Ñ¢.\\xa0\\nAnother Win for AutoNAC\\n\\nto previous SOTA on COCOSuperGradients star historyDesigning the BlueprintInspired by the success of modern YOLO architectures, our team set out to create a new quantization-friendly architecture - and it all started with Neural Architecture Search (NAS).NAS:Everything You Need to KnowThe first thing you need to do when performing Neural Architecture Search is define the architecture search space. For YOLO-NAS, our researchers took inspiration from the basic blocks of YOLOv6 and YOLOv8. With\\n\\nUtilizing our proprietary neural architecture search (NAS) algorithm, The Automated Neural Architecture Construction (AutoNAC) engine, our research team discovered a new architecture that outperforms YOLOv8.\\n\\nThe quest for the ‚Äúoptimal‚Äù neural network architecture has historically been a labor-intensive manual exploration. While this manual approach often yields results, it is highly time consuming and often falls short in pinpointing the most efficient neural networks. The AI community recognized the promise of Neural Architecture Search (NAS) as a potential game-changer, automating the development of superior neural networks. However, the computational demands of traditional NAS methods limited\\n\\nQuestion: What does Neural Architecture Search have to do with how Deci creates its models?\\nHelpful Answer: Neural Architecture Search (NAS) is a technique used by Deci to automatically discover the optimal neural network architecture for its models, such as DeciCoder, using its proprietary AutoNAC algorithm. This approach allows Deci to create more efficient and accurate models than manually designing them.\",\n",
       " 'source_documents': [Document(page_content='Deci‚Äôs suite of Large Language Models and text-to-Image models, with DeciCoder leading the charge, is spearheading the movement to address this gap.DeciCoder‚Äôs efficiency is evident when compared to other top-tier models. Owing to its innovative architecture, DeciCoder surpasses models like SantaCoder in both accuracy and speed. The innovative elements of DeciCoder‚Äôs architecture were generated using Deci‚Äôs proprietary Neural Architecture Search technology, AutoNAC‚Ñ¢.\\xa0\\nAnother Win for AutoNAC', metadata={'source': 'https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/', 'title': 'Introducing DeciCoder: The New Gold Standard in Efficient and Accurate Code Generation', 'description': 'Today, we introduce DeciCoder, our 1B-parameter open-source Large Language Model for code generation, equipped with a 2048-context window.', 'language': 'en-US'}),\n",
       "  Document(page_content='to previous SOTA on COCOSuperGradients star historyDesigning the BlueprintInspired by the success of modern YOLO architectures, our team set out to create a new quantization-friendly architecture - and it all started with Neural Architecture Search (NAS).NAS:Everything You Need to KnowThe first thing you need to do when performing Neural Architecture Search is define the architecture search space. For YOLO-NAS, our researchers took inspiration from the basic blocks of YOLOv6 and YOLOv8. With', metadata={'source': 'https://deeplearningdaily.substack.com/p/unleashing-the-power-of-yolo-nas', 'title': 'Unleashing the Power of YOLO-NAS: A New Era in Object Detection and Computer Vision', 'description': 'The Future of Computer Vision is Here', 'language': 'en'}),\n",
       "  Document(page_content='Utilizing our proprietary neural architecture search (NAS) algorithm, The Automated Neural Architecture Construction (AutoNAC) engine, our research team discovered a new architecture that outperforms YOLOv8.', metadata={'source': 'https://deci.ai/blog/yolo-nas-object-detection-foundation-model/', 'title': 'YOLO-NAS by Deci Achieves State-of-the-Art Performance on Object Detection Using Neural Architecture Search', 'description': 'The new YOLO-NAS architecture sets a new frontier for object detection tasks, offering the best accuracy and latency tradeoff performance.', 'language': 'en-US'}),\n",
       "  Document(page_content='The quest for the ‚Äúoptimal‚Äù neural network architecture has historically been a labor-intensive manual exploration. While this manual approach often yields results, it is highly time consuming and often falls short in pinpointing the most efficient neural networks. The AI community recognized the promise of Neural Architecture Search (NAS) as a potential game-changer, automating the development of superior neural networks. However, the computational demands of traditional NAS methods limited', metadata={'source': 'https://deci.ai/blog/decicoder-efficient-and-accurate-code-generation-llm/', 'title': 'Introducing DeciCoder: The New Gold Standard in Efficient and Accurate Code Generation', 'description': 'Today, we introduce DeciCoder, our 1B-parameter open-source Large Language Model for code generation, equipped with a 2048-context window.', 'language': 'en-US'})]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Neural Architecture Search (NAS) is a technique used by Deci to automatically discover the optimal neural network architecture for its models, such as DeciCoder, using its proprietary AutoNAC algorithm. This approach allows Deci to create more efficient and accurate models than manually designing them.\n"
     ]
    }
   ],
   "source": [
    "print(response['result'].split(':')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_apps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
